---
title: "part 3"
output: html_notebook
---

In this problem, we will use a dataset comprised of google reviews on attractions from 23 categories. Google user ratings range from 1 to 5 and average user ratings per category is pre-calculated. The data set is populated by capturing user ratings from Google reviews. Reviews on attractions from 23 categories across Europe are considered.  Each observation represents a user.

**Dataset: ratings.csv**

Our dataset has the following columns:

**userId**: a unique integer identifying a user
**churches, resorts, beaches,..,monuments, gardens**: the average rating that this user has rated any attraction corresponding to these categories.  For example, the user with **userID** = User 1 has **parks** = 3.65, which means that the average rating of all the parks this user rated is 3.65.  It can be assumed that if an average rating is 0, then that is the average rating. It is not the case that the user has not rated that category.

In this problem, we aim to cluster users by their average rating per category. Hence, users in the same cluster tend to enjoy or dislike the same categories.
________________________________________________________________________________________________________________
# Problem 1 - Exploratory Data Analysis
Read the dataset ratings.csv into a dataframe called ratings.
*How many users are in the dataset?*
```{r}
ratings = read.csv("Desktop/MITx 15.071x - Analyticse Edge/Final Exam /ratings.csv")
str(ratings)
summary(ratings$userid)
```
>5456 users in the dataset.

*How many categories are rated in the dataset?*
```{r}
str(ratings)
```
>23 genres in the dataset

*Note that there are some NA's in the data. Which columns have missing data?*
```{r}
colnames(is.na(ratings))
!colSums(is.na(ratings))
```
> Gardens & Burger_shops

*What will happen if NA values are replaced with the value 0?*
> Categories with missing values will be penalized.

o deal with the missing values, we will simply remove the observations with the missing values first (there are more sophisticated ways to work with missing values, but for this purpose removing the observations is fine since we do not lose a significant amount of observations). Run the following code:
**ratings = ratings[rowSums(is.na(ratings)) == 0, ]**
```{r}
str(ratings)
```
> 5456

Which category has the highest mean score?
```{r}
summary(ratings)
```
> Malls

# Problem 2 - Preparing the Data
*Before performing clustering on the dataset, which variable(s) should be removed?*
> UserID

Remove the necessary column from the dataset and rename the new data frame points.Now, we will normalize the data.
*What will the maximum value of pubs be after applying mean-var normalization?* Answer without actually normalizing the data.
```{r}
ratings$userid <- NULL
str(ratings)
```
>

Normalize the data using the following code:
**library(caret)**
**preproc = preProcess(points)**
**pointsnorm = predict(preproc, points)**
*What is the maximum value of juice_bars after the normalization?*
```{r}
library(caret)
preproc = preProcess(ratings)
pointsnorm = predict(preproc, ratings)

max(pointsnorm$juice_bars)
```
> 1.781673

# Problem 3.1 - Clustering

Create a dendogram using the following code:
**distances = dist(pointsnorm, method = "euclidean")**
**dend = hclust(distances, method = "ward.D")**
**plot(dend, labels = FALSE)**
*Based on the dendrogram, how many clusters do you think would NOT be appropriate for this problem?*
> 5

Based on this dendogram, in choosing the number of clusters, what is the best option?
> 4

# Problem 3.2 - Clustering
Set the random seed to 100, and run the k-means clustering algorithm on your normalized dataset, setting the number of clusters to 4.
*How many observations are in the largest cluster?*
```{r}
set.seed(100)
kmc = kmeans(pointsnorm, centers = 4)
KmeansCluster1 = subset(pointsnorm, kmc$cluster == 1)

KmeansCluster2 = subset(pointsnorm, kmc$cluster == 2)

KmeansCluster3 = subset(pointsnorm, kmc$cluster == 3)

KmeansCluster4 = subset(pointsnorm, kmc$cluster == 4)

KmeansCluster5 = subset(pointsnorm, kmc$cluster == 5)

nrow(KmeansCluster1)
nrow(KmeansCluster2)
nrow(KmeansCluster3)
nrow(KmeansCluster4)
nrow(KmeansCluster5)

```
> 1996

# Problem 4 - Conceptual Questions
*True or False: If we ran k-means clustering a second time without making any additional calls to set.seed, we would expect every observation to be in the same cluster as it is now.*
> False

*True or False: K-means clustering is sensative to outliers.*
>True

*Why do we typically use cluster centroids to describe the clusters?*
> The cluster centroid captures the average behavior in the cluster, and can be used to summarize the general pattern in the cluster.

*Is "overfitting" a problem in clustering?*
> Yes, at the extreme every data point can be assigned to its own cluster.

*Is "multicollinearity" a problem in clustering?*
> Yes, multicollinearity could cause certain features to be overweighted in the distances calculations.


# Problem 5 - Understanding the Clusters

*Which cluster has the user with the lowest average rating in restaurants?*
> Cluster 4

*Which of the clusters is best described as "users who have mostly enjoyed churches, pools, gyms, bakeries, and cafes"?*
> Cluster 1

*Which cluster seems to enjoy being outside, but does not enjoy as much going to the zoo or pool?*
> Cluster 4



